# Promptchain
## Exploring and testing different methods of chaining prompts to satisfy requirements for more complex LLM tasks - with a single prompt
---
This project combines different ideas from existing papers on large language models to create a more powerful, language based algorithm. We are combining methods like Chain of Thought (CoT), reflection and correction, vector databases and rankers to improve results of transformers like GPT.\
It has been proven that the listed methods on their own improve performance of LLMs, thus it is logical to assume that chaining them would yield even better results.\
The goal is to build algorithms which are partially autonomous and can read and write files to repositories, solve very complex multi-step tasks or even think like humans do. In this probabilistic "Langramming" approach, in which we fuse language models with programming, a new frontier of modern development is discovered.
